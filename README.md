ğŸ§  Brain Tumor Classification Using Vision Transformers (ViT, CrossViT, CaiT)
This project presents a comparative study of Vision Transformer (ViT) models â€” including ViT, CrossViT, and CaiT â€” for the classification of brain tumors from MRI images. The focus is on applying recent advancements in Transformer-based architectures to improve accuracy and reliability in medical image classification.

ğŸ—‚ï¸ Dataset
The models were trained and evaluated on the Brain MRI dataset from Kaggle, which consists of brain MRI scans categorized into four classes:

Glioma

Meningioma

Pituitary

No Tumor

ğŸ”„ Preprocessing & Augmentation
To improve generalization and reduce overfitting, the following preprocessing techniques were applied:

Image resizing to 224Ã—224 pixels

Normalization to match ImageNet standards

Data augmentation including random rotation, flipping, zooming, and brightness adjustment

ğŸ§ª Models Compared
Vision Transformer (ViT) â€“ Standard self-attention-based model for image classification

CrossViT â€“ Fuses multi-scale image features for better local-global context

CaiT (Class-Attention in Image Transformers) â€“ Deep transformer with improved class token dynamics and layer scaling

ğŸ“Š Performance Summary
Model	Accuracy	Notes
ViT	~93%	Strong baseline performance
CrossViT	~95%	Best performer with superior multi-scale fusion
CaiT	~94%	Deep architecture, competitive performance

ğŸš€ CrossViT outperformed others, likely due to its ability to capture both local and global features effectively.

âœ… Key Highlights
Demonstrates how transformer models can outperform traditional CNNs on medical imaging tasks

Fully implemented in a Google Colab Jupyter notebook

Uses PyTorch with GPU support

Easy to adapt to other medical imaging tasks

